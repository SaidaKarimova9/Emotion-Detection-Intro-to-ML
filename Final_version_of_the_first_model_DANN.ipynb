{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMr7LY4QCct1BKpPkZJMkkd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaidaKarimova9/DSD-Final-Project/blob/main/Final_version_of_the_first_model_DANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC95j3qK0MzW",
        "outputId": "5241e846-a434-4614-a012-5a3183fb763a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install numpy pandas matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUiQI3f21RnL",
        "outputId": "923d518f-d841-45d1-dfa1-320705c949e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Paths to the zip files\n",
        "zip_paths = [\n",
        "    '/content/drive/MyDrive/ML-2024/AFE.zip',\n",
        "    '/content/drive/MyDrive/ML-2024/ExpW.zip'\n",
        "]\n",
        "\n",
        "# Extract each zip file\n",
        "for zip_path in zip_paths:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/dataset')"
      ],
      "metadata": {
        "id": "93__34kz1Yls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Function\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "class ResizeAndPad:\n",
        "    def __init__(self, size, interpolation=Image.BILINEAR):\n",
        "        self.size = size\n",
        "        self.interpolation = interpolation\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img.thumbnail((self.size, self.size), self.interpolation)\n",
        "        delta_w = self.size - img.size[0]\n",
        "        delta_h = self.size - img.size[1]\n",
        "        padding = (delta_w // 2, delta_h // 2, delta_w - (delta_w // 2), delta_h - (delta_h // 2))\n",
        "        return transforms.functional.pad(img, padding, fill=0)\n",
        "\n",
        "class FilteredImageFolder(datasets.ImageFolder):\n",
        "    def __init__(self, root, transform=None, min_size=32):\n",
        "        super().__init__(root, transform=transform)\n",
        "        self.min_size = min_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, target = self.samples[index]\n",
        "        sample = self.loader(path)\n",
        "        if min(sample.size) < self.min_size:\n",
        "            return None\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(sample)\n",
        "        return sample, target\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    ResizeAndPad(128),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    ResizeAndPad(128),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Paths to the datasets\n",
        "source_train_path = '/content/dataset/AFE/train'\n",
        "source_test_path = '/content/dataset/AFE/test'\n",
        "target_train_path = '/content/dataset/ExpW/train'\n",
        "target_test_path = '/content/dataset/ExpW/test'\n",
        "\n",
        "# Load datasets\n",
        "source_train_dataset = FilteredImageFolder(root=source_train_path, transform=train_transform)\n",
        "source_test_dataset = FilteredImageFolder(root=source_test_path, transform=transform)\n",
        "target_train_dataset = FilteredImageFolder(root=target_train_path, transform=train_transform)\n",
        "target_test_dataset = FilteredImageFolder(root=target_test_path, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "source_train_loader = DataLoader(source_train_dataset, batch_size=32, shuffle=True)\n",
        "source_test_loader = DataLoader(source_test_dataset, batch_size=32, shuffle=False)\n",
        "target_train_loader = DataLoader(target_train_dataset, batch_size=32, shuffle=True)\n",
        "target_test_loader = DataLoader(target_test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "        return output, None\n",
        "\n",
        "class DANN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(DANN, self).__init__()\n",
        "        self.feature = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25),\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Dropout(0.25),\n",
        "        )\n",
        "\n",
        "        self.class_classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 16 * 16, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes),\n",
        "        )\n",
        "\n",
        "        self.domain_classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 16 * 16, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_data, alpha):\n",
        "        input_data = input_data.expand(input_data.data.shape[0], 3, 128, 128)\n",
        "        feature = self.feature(input_data)\n",
        "        feature = feature.view(-1, 512 * 16 * 16)\n",
        "        reverse_feature = ReverseLayerF.apply(feature, alpha)\n",
        "        class_output = self.class_classifier(feature)\n",
        "        domain_output = self.domain_classifier(reverse_feature)\n",
        "        return class_output, domain_output\n",
        "\n",
        "# Training configuration\n",
        "num_classes = 7\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "alpha = 0.3\n",
        "\n",
        "# Define the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create the model\n",
        "model = DANN(num_classes=num_classes).to(device)\n",
        "\n",
        "# Define the loss functions and optimizer\n",
        "criterion_class = nn.CrossEntropyLoss()\n",
        "criterion_domain = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "6qtP1xCe1z-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def load_checkpoint(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    return checkpoint['epoch']\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/ML-2024/checkpoint.pth'\n",
        "start_epoch = load_checkpoint(checkpoint_path)\n",
        "print(f\"Resumed from epoch {start_epoch}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZCtJWSo4uCX",
        "outputId": "446e4268-b4b8-48ff-d930-e8730785fca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumed from epoch 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs, _ = model(images, alpha=0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate on source and target test datasets\n",
        "source_accuracy = evaluate(model, source_test_loader, device)\n",
        "target_accuracy = evaluate(model, target_test_loader, device)\n",
        "\n",
        "print(f'Resumed Source Test Accuracy: {source_accuracy * 100:.2f}%')\n",
        "print(f'Resumed Target Test Accuracy: {target_accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "def save_results(phase, source_accuracy, target_accuracy):\n",
        "    results = {\n",
        "        'phase': phase,\n",
        "        'source_accuracy': source_accuracy,\n",
        "        'target_accuracy': target_accuracy\n",
        "    }\n",
        "    torch.save(results, f'/content/drive/MyDrive/ML-2024/{phase}_results.pth')\n",
        "\n",
        "# Save the resumed evaluation results\n",
        "save_results('resumed_final', source_accuracy, target_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvMKwoec5rcB",
        "outputId": "7d7c971e-5299-452f-ec4d-1b40083e0ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumed Source Test Accuracy: 76.94%\n",
            "Resumed Target Test Accuracy: 26.13%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_dir = '/content/drive/MyDrive/ML-2024/saved_models'\n",
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "3nBfP3K-F-Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(model, optimizer, epoch, filepath):\n",
        "    state = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(state, filepath)\n"
      ],
      "metadata": {
        "id": "Ihrb0qofF_Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Training\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for target_batch, target_labels in target_train_loader:\n",
        "        target_batch, target_labels = target_batch.to(device), target_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        outputs, _ = model(target_batch, alpha=0)\n",
        "        loss = criterion_class(outputs, target_labels)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "    # Save the oracle model checkpoint\n",
        "    save_checkpoint(model, optimizer, epoch, f'{save_dir}/oracle_epoch_{epoch+1}.pth')\n",
        "\n",
        "print(\"Target Only Training finished.\")\n",
        "\n",
        "# Evaluate on target test set\n",
        "target_only_accuracy = evaluate(model, target_test_loader, device)\n",
        "print(f'Oracle Target Test Accuracy: {target_only_accuracy * 100:.2f}%')\n",
        "\n",
        "# Save final oracle results\n",
        "save_results('oracle_final', target_only_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "TiKclSdLGCj-",
        "outputId": "d8b2df0a-6687-4934-a495-ddfd2a5e7186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 2.456855099588152\n",
            "Epoch [2/20], Loss: 1.708629955026892\n",
            "Epoch [3/20], Loss: 1.5219264399380452\n",
            "Epoch [4/20], Loss: 1.4333691099478352\n",
            "Epoch [5/20], Loss: 1.3872605704311882\n",
            "Epoch [6/20], Loss: 1.3509853784475596\n",
            "Epoch [7/20], Loss: 1.3290659583984845\n",
            "Epoch [8/20], Loss: 1.3075199122991292\n",
            "Epoch [9/20], Loss: 1.2905153452508873\n",
            "Epoch [10/20], Loss: 1.2763189351366413\n",
            "Epoch [11/20], Loss: 1.260695050019891\n",
            "Epoch [12/20], Loss: 1.2495153453501482\n",
            "Epoch [13/20], Loss: 1.2374753599625923\n",
            "Epoch [14/20], Loss: 1.234949983956833\n",
            "Epoch [15/20], Loss: 1.2235182180940625\n",
            "Epoch [16/20], Loss: 1.2145985764481368\n",
            "Epoch [17/20], Loss: 1.2079134402315943\n",
            "Epoch [18/20], Loss: 1.1988428696208904\n",
            "Epoch [19/20], Loss: 1.1940884230237814\n",
            "Epoch [20/20], Loss: 1.1856541344595533\n",
            "Target Only Training finished.\n",
            "Oracle Target Test Accuracy: 65.07%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "save_results() missing 1 required positional argument: 'target_accuracy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1d3d752679cf>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Save final oracle results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0msave_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'oracle_final'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_only_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: save_results() missing 1 required positional argument: 'target_accuracy'"
          ]
        }
      ]
    }
  ]
}