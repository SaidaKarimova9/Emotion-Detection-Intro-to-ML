{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNJloMxUhVO9qEAhWTf78BI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaidaKarimova9/Emotion-Detection-Intro-to-ML/blob/main/The_Final_version_of_the_second_model_Maximum_Classifier_Discrepancy_(MCD)ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxd8lpQyJ_KG",
        "outputId": "7babf834-89ed-48bc-cf72-8ec09677a565"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib torch torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dj4h1JxcKL0S",
        "outputId": "d271d183-a6bb-4acb-ceed-9bfe669139ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "EMQCVSWWg3Il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "afe_zip_path = '/content/drive/MyDrive/ML-2024/AFE.zip'\n",
        "expw_zip_path = '/content/drive/MyDrive/ML-2024/ExpW.zip'\n",
        "\n",
        "with zipfile.ZipFile(afe_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/AFE')\n",
        "\n",
        "with zipfile.ZipFile(expw_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/ExpW')\n"
      ],
      "metadata": {
        "id": "3t0TyVSKOipC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "source_train_data = datasets.ImageFolder('/content/AFE/AFE/train', transform=data_transform)\n",
        "source_test_data = datasets.ImageFolder('/content/AFE/AFE/test', transform=data_transform)\n",
        "\n",
        "target_train_data = datasets.ImageFolder('/content/ExpW/ExpW/train', transform=data_transform)\n",
        "target_test_data = datasets.ImageFolder('/content/ExpW/ExpW/test', transform=data_transform)\n"
      ],
      "metadata": {
        "id": "sQkGixLHPMgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "source_train_loader = DataLoader(source_train_data, batch_size=batch_size, shuffle=True)\n",
        "source_test_loader = DataLoader(source_test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "target_train_loader = DataLoader(target_train_data, batch_size=batch_size, shuffle=True)\n",
        "target_test_loader = DataLoader(target_test_data, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "O5rvrQkvPj5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "        self.backbone = models.resnet50(pretrained=True)\n",
        "        self.backbone.fc = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.backbone(x)\n",
        "        return features\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "VnnPX9SGPoLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "feature_extractor = FeatureExtractor().to(device)\n",
        "classifier1 = Classifier(num_classes=7).to(device)\n",
        "classifier2 = Classifier(num_classes=7).to(device)\n",
        "\n",
        "optimizer_f = optim.Adam(feature_extractor.parameters(), lr=1e-4)\n",
        "optimizer_c1 = optim.Adam(classifier1.parameters(), lr=1e-4)\n",
        "optimizer_c2 = optim.Adam(classifier2.parameters(), lr=1e-4)\n",
        "\n",
        "def train_source():\n",
        "    feature_extractor.train()\n",
        "    classifier1.train()\n",
        "    classifier2.train()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        for images, labels in source_train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            features = feature_extractor(images)\n",
        "            outputs1 = classifier1(features)\n",
        "            outputs2 = classifier2(features)\n",
        "\n",
        "            loss1 = F.cross_entropy(outputs1, labels)\n",
        "            loss2 = F.cross_entropy(outputs2, labels)\n",
        "            loss = loss1 + loss2\n",
        "\n",
        "            optimizer_f.zero_grad()\n",
        "            optimizer_c1.zero_grad()\n",
        "            optimizer_c2.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_f.step()\n",
        "            optimizer_c1.step()\n",
        "            optimizer_c2.step()\n",
        "\n",
        "def adapt_target():\n",
        "    feature_extractor.train()\n",
        "    classifier1.eval()\n",
        "    classifier2.eval()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        for images, _ in target_train_loader:\n",
        "            images = images.to(device)\n",
        "            features = feature_extractor(images)\n",
        "            outputs1 = classifier1(features)\n",
        "            outputs2 = classifier2(features)\n",
        "\n",
        "            discrepancy = torch.mean(torch.abs(F.softmax(outputs1, dim=1) - F.softmax(outputs2, dim=1)))\n",
        "\n",
        "            optimizer_f.zero_grad()\n",
        "            discrepancy.backward()\n",
        "            optimizer_f.step()\n",
        "\n",
        "train_source()\n",
        "adapt_target()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsFxvrmYPreq",
        "outputId": "3a2d15dc-88f5-4d83-f950-b7a31677108e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 193MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(loader, feature_extractor, classifier):\n",
        "    feature_extractor.eval()\n",
        "    classifier.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            features = feature_extractor(images)\n",
        "            outputs = classifier(features)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    return 100 * correct / total\n",
        "\n",
        "source_acc = evaluate(source_test_loader, feature_extractor, classifier1)\n",
        "target_acc = evaluate(target_test_loader, feature_extractor, classifier1)\n",
        "\n",
        "print(f'Source Accuracy: {source_acc}%')\n",
        "print(f'Target Accuracy: {target_acc}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE7cdXNrZQys",
        "outputId": "aca7b009-fe6a-4d32-db18-b30507f0dd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Accuracy: 48.44522579936271%\n",
            "Target Accuracy: 40.68055210587943%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_target():\n",
        "    feature_extractor.train()\n",
        "    classifier1.train()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        for images, labels in target_train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            features = feature_extractor(images)\n",
        "            outputs = classifier1(features)\n",
        "\n",
        "            loss = F.cross_entropy(outputs, labels)\n",
        "\n",
        "            optimizer_f.zero_grad()\n",
        "            optimizer_c1.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer_f.step()\n",
        "            optimizer_c1.step()\n",
        "\n",
        "train_target()\n",
        "\n",
        "target_oracle_acc = evaluate(target_test_loader, feature_extractor, classifier1)\n",
        "print(f'Target Oracle Accuracy: {target_oracle_acc}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT0G3RTXZ644",
        "outputId": "f8955331-e823-452f-a5c5-c8bd32fc1eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Oracle Accuracy: 86.56991803569528%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    'Dataset': ['Source (AFE)', 'Target (ExpW)', 'Target Oracle (ExpW)'],\n",
        "    'Accuracy': [source_acc, target_acc, target_oracle_acc]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DENX3Dn8galF",
        "outputId": "1fd16fe8-f0e2-4f50-cacb-7eddccca9355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Dataset   Accuracy\n",
            "0          Source (AFE)  48.445226\n",
            "1         Target (ExpW)  40.680552\n",
            "2  Target Oracle (ExpW)  86.569918\n"
          ]
        }
      ]
    }
  ]
}